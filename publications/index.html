<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Mostafa  Ghorbandoost | publications</title>
<meta name="description" content="Mostafa Ghorbandoost
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/publications/">

<!-- Theming-->


    
<!-- MathJax -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="http://localhost:4000/">
       <span class="font-weight-bold">Mostafa</span>   Ghorbandoost
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/bio/">
                bio
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <p class="post-description"></p>
  </header>

  <article>
    <div class="publications">


  <h2 class="year">2017</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">IEEE Conference</abbr>
    
  
  </div>

  <div id="WASSPA" class="col-sm-8">
    
      <div class="title">Voice conversion based on a mixture density network</div>
      <div class="author">
        
          
            
              
                
                  <a href="https://scholar.google.com/citations?user=AumoodsAAAAJ&amp;hl=en" target="_blank">Ahangar, Mohsen</a>,
                
              
            
          
        
          
            
              
                <em>Ghorbandoost, Mostafa</em>,
              
            
          
        
          
            
              
                
                  <a href="https://www.linkedin.com/in/sudhendu-sharma-67034823" target="_blank">Sharma, Sudhendu</a>,
                
              
            
          
        
          
            
              
                
                  and <a href="http://www.ece.utexas.edu/people/faculty/mark-jt-smith" target="_blank">Smith, Mark JT</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA), New Paltz, NY, USA</em>
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
      <a href="https://ieeexplore.ieee.org/document/8170049" class="btn btn-sm z-depth-0" role="button" target="_blank">Link</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This paper presents a new voice conversion (VC) algorithm based on a Mixture Density Network (MDN). MDN is the combination of a Gaussian Mixture Model (GMM) and an Artificial Neural Network (ANN), where the parameters of the GMM are estimated by using the ANN method instead of the Expectation Maximization (EM) algorithm. This characteristic helps the MDN estimate GMM parameters more accurately, which results in lower distortion in the converted speech. To apply the MDN to VC, we combine the MDN with Maximum Likelihood Estimation, employing a Global Variance modification (MLE-GV) method. Objective results show better performance for the proposed MDN method compared with MLE and Joint Density GMM (JDGMM) methods. Subjective experiments demonstrate that the proposed method outperforms the MLE-GV and JDGMM-GV in terms of speech quality and speaker individuality.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">IET Journal</abbr>
    
  
  </div>

  <div id="IET" class="col-sm-8">
    
      <div class="title">Non-parallel training for voice conversion using background-based alignment of GMMs and INCA algorithm</div>
      <div class="author">
        
          
            
              
                <em>Ghorbandoost, Mostafa</em>,
              
            
          
        
          
            
              
                
                  and <a href="https://scholar.google.com/citations?user=gD0ntK0AAAAJ&amp;hl=en" target="_blank">Saba, Valiallah</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IET Signal Processing</em>
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
      <a href="https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/iet-spr.2016.0693" class="btn btn-sm z-depth-0" role="button" target="_blank">Link</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Most of the voice conversion (VC) researches have used parallel training corpora to train the conversion function. However, in practice it is not always possible to gather parallel corpora, so the need for non-parallel training methods arises. As a successful non-parallel method, nearest neighbour search step and a conversion step alignment method (INCA) algorithm has attracted a lot of attention in recent years. In this study, the authors propose a new method of non-parallel VC which is based on the INCA algorithm. The authors’ method effectively solves the initialisation problem of INCA algorithm. Their proposed initialisation for INCA is done with alignment of Gaussian mixture models (GMM) using universal background model. Results of objective and subjective experiments determined that the authors’ proposed method improves the INCA algorithm. It is observed that this superiority holds for different sizes of training material from 10 to 50 training sentences. In terms of mean opinion score, the authors’ method scores 0.25 higher in the case of quality and 0.2 higher in the case of similarity to the target speaker compared with traditional INCA. It seems that the authors’ proposed method is a suitable frame alignment method for non-parallel corpora in VC task.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2015</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ELSEVIER</abbr>
    
  
  </div>

  <div id="ELSEVIER" class="col-sm-8">
    
      <div class="title">Voice conversion based on feature combination with limited training data</div>
      <div class="author">
        
          
            
              
                <em>Ghorbandoost, Mostafa</em>,
              
            
          
        
          
            
              
                
                  <a href="https://aut.ac.ir/cv/2560/Abolghasam%20Saiadian" target="_blank">Sayadiyan, Abolghasem</a>,
                
              
            
          
        
          
            
              
                
                  <a href="https://scholar.google.com/citations?user=AumoodsAAAAJ&amp;hl=en" target="_blank">Ahangar, Mohsen</a>,
                
              
            
          
        
          
            
              
                
                  <a href="https://scholar.google.com/citations?user=tLX51p0AAAAJ&amp;hl=en" target="_blank">Sheikhzadeh, Hamid</a>,
                
              
            
          
        
          
            
              
                
                  <a href="https://scholar.google.com/citations?user=zQPhuX8AAAAJ&amp;hl=en" target="_blank">Shahrebabaki, Abdoreza Sabzi</a>,
                
              
            
          
        
          
            
              
                
                  and <a href="https://scholar.google.com/citations?user=zhcdyLMAAAAJ&amp;hl=en" target="_blank">Amini, Jamal</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Speech Communication</em>
      
      
        2015
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
      <a href="https://www.sciencedirect.com/science/article/abs/pii/S0167639314000892" class="btn btn-sm z-depth-0" role="button" target="_blank">Link</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Typically, voice conversion systems just use one type of spectral feature to convert acoustical characteristics of one speaker to another speaker. In this paper, we first study four different spectral features. Then, we compare these features and choose two features that perform better than others. Our experiments showed that cepstral features are more suitable than all-pole features for clustering and all-pole features are better for the analysis/synthesis stages. Hence, we propose a new voice conversion algorithm that uses both cepstral and all-pole features in order to utilize their desired properties simultaneously. We have two ideas to utilize this feature combination strategy. Our first idea is to apply feature combination to classical Gaussian mixture models (GMM)-based voice conversion method. The second idea is to apply feature combination to dynamic kernel partial least square regression (DKPLS) method. Results of our evaluations show that our proposed methods outperform the modern voice conversion methods in terms of speech quality and speaker individuality. Our methods are also robust to limited training data.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2013</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">IEEE Conference</abbr>
    
  
  </div>

  <div id="ISSPIT" class="col-sm-8">
    
      <div class="title">Voice conversion based on state space model and considering global variance</div>
      <div class="author">
        
          
            
              
                
                  <a href="https://scholar.google.com/citations?user=AumoodsAAAAJ&amp;hl=en" target="_blank">Ahangar, Mohsen</a>,
                
              
            
          
        
          
            
              
                <em>Ghorbandoost, Mostafa</em>,
              
            
          
        
          
            
              
                
                  <a href="https://scholar.google.com/citations?user=tLX51p0AAAAJ&amp;hl=en" target="_blank">Sheikhzadeh, Hamid</a>,
                
              
            
          
        
          
            
              
                
                  <a href="https://scholar.google.ca/citations?user=ZN9aBZcAAAAJ&amp;hl=en" target="_blank">Raahemifar, Kaamran</a>,
                
              
            
          
        
          
            
              
                
                  <a href="https://scholar.google.com/citations?user=zQPhuX8AAAAJ&amp;hl=en" target="_blank">Shahrebabaki, Abdoreza Sabzi</a>,
                
              
            
          
        
          
            
              
                
                  and <a href="https://scholar.google.com/citations?user=zhcdyLMAAAAJ&amp;hl=en" target="_blank">Amini, Jamal</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In IEEE International Symposium on Signal Processing and Information Technology (ISSPIT), Athens, Greece</em>
      
      
        2013
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
      <a href="https://ieeexplore.ieee.org/document/6781917" class="btn btn-sm z-depth-0" role="button" target="_blank">Link</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Voice conversion based on State Space Model (SSM) has been recently proposed to address the discontinuity problem in the traditional frame-based voice conversion by considering the spectral envelope evolutions. However, the results are over-smoothed. To resolve this problem, in this paper we propose a new procedure for integrating the global variance constraint into the SSM-based voice conversion. Moreover, unlike the SSM-based method, we allow the state-vector order to be higher than the feature-vector order. Experimental results verify that the proposed method significantly improves the performance of the SSM-based voice conversion in terms of speaker individuality and speech quality. Our experiments also show that the proposed method outperforms the well-known Maximum Likelihood estimation method that considers the Global Variance in terms of speech quality.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Springer</abbr>
    
  
  </div>

  <div id="NOLISP" class="col-sm-8">
    
      <div class="title">Reduced Search Space Frame Alignment Based on Kullback-Leibler Divergence for Voice Conversion</div>
      <div class="author">
        
          
            
              
                
                  <a href="https://scholar.google.com/citations?user=zQPhuX8AAAAJ&amp;hl=en" target="_blank">Shahrebabaki, Abdoreza Sabzi</a>,
                
              
            
          
        
          
            
              
                
                  <a href="https://scholar.google.com/citations?user=zhcdyLMAAAAJ&amp;hl=en" target="_blank">Amini, Jamal</a>,
                
              
            
          
        
          
            
              
                
                  <a href="https://scholar.google.com/citations?user=tLX51p0AAAAJ&amp;hl=en" target="_blank">Sheikhzadeh, Hamid</a>,
                
              
            
          
        
          
            
              
                <em>Ghorbandoost, Mostafa</em>,
              
            
          
        
          
            
              
                
                  and <a href="https://scholar.google.com/citations?user=y4t_cGgAAAAJ&amp;hl=en" target="_blank">Faraji, Neda</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Conference on Nonlinear Speech Processing, Mons, Belgium</em>
      
      
        2013
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
      <a href="https://link.springer.com/chapter/10.1007/978-3-642-38847-7_11" class="btn btn-sm z-depth-0" role="button" target="_blank">Link</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>A new text independent voice conversion based on Kullback-Leibler divergence (KLD) is proposed. This method only uses acoustic information and does not require any linguistic or phonetic information. The KLD is used to find reliable correspondence between the source and target GMM clusters and to reduce the search space for alignment of source and target frames. Subjective evaluation results show that the proposed method can achieve the same performance as parallel voice conversion methods.</p>
    </div>
    
  </div>
</div>
</li></ol>


</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2021 Mostafa  Ghorbandoost.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme.

    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  



<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>


</html>
